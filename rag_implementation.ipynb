{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG application for game research \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# LangSmith imports for tracing\n",
    "from langsmith import traceable\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_game_name(query: str, games_csv_path: str = \"games.csv\") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extract game name from a user query by checking against a CSV file of game names.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's query text\n",
    "        games_csv_path: Path to CSV file containing game names\n",
    "        \n",
    "    Returns:\n",
    "        The extracted game name or None if no game found\n",
    "    \"\"\"\n",
    "    # Check if CSV file exists\n",
    "    if not os.path.exists(games_csv_path):\n",
    "        print(f\"Warning: Games CSV file {games_csv_path} not found.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load game names from CSV\n",
    "        games_df = pd.read_csv(games_csv_path, header=None)\n",
    "        game_names = games_df[0].tolist()  # Assuming the game names are in the first column\n",
    "        \n",
    "        # Normalize query for matching\n",
    "        normalized_query = query.lower()\n",
    "        \n",
    "        # Sort game names by length (descending) to prioritize longer matches\n",
    "        for game in sorted(game_names, key=len, reverse=True):\n",
    "            # Check for case-insensitive match\n",
    "            if game.lower() in normalized_query:\n",
    "                return game\n",
    "        \n",
    "        # Enhanced detection with patterns\n",
    "        patterns = [\n",
    "            r\"for\\s+(.+?)(?:\\s+game|\\s+reviews|\\s+in|\\?|$)\",  # \"for [game]\"\n",
    "            r\"about\\s+(.+?)(?:\\s+game|\\s+reviews|\\?|$)\",      # \"about [game]\"\n",
    "            r\"in\\s+(.+?)(?:\\s+game|\\s+reviews|\\?|$)\",         # \"in [game]\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.search(pattern, normalized_query)\n",
    "            if matches:\n",
    "                potential_game = matches.group(1).strip()\n",
    "                # Find the closest match in our game list\n",
    "                for game in game_names:\n",
    "                    if potential_game in game.lower() or game.lower() in potential_game:\n",
    "                        return game\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting game name: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"setup_rag_retriever\")\n",
    "def setup_rag_retriever(\n",
    "    collection_name: str = \"steam_reviews\",\n",
    "    openai_api_key: str = None,\n",
    "    embedding_model: str = \"text-embedding-3-small\",\n",
    "    search_type: str = \"similarity\",\n",
    "    k: int = 4,\n",
    "    game_name: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Set up a langchain retriever from an existing Qdrant collection with tracing.\n",
    "    Adds ability to filter by game name.\n",
    "    \"\"\"\n",
    "    if openai_api_key is None:\n",
    "        openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "        \n",
    "    # Setup embeddings\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=embedding_model,\n",
    "        openai_api_key=openai_api_key\n",
    "    )\n",
    "    \n",
    "    # Connect to existing Qdrant collection\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "    \n",
    "    # Create a filter if game_name is provided using the exact dictionary format from Qdrant docs\n",
    "    search_kwargs = {\"k\": k}\n",
    "    if game_name:\n",
    "        # This is the correct filter format according to Qdrant documentation\n",
    "        search_kwargs[\"filter\"] = {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"key\": \"game_name\",\n",
    "                    \"match\": {\n",
    "                        \"value\": game_name\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        print(f\"Filtering for game: {game_name}\")\n",
    "    \n",
    "    # Create vector store with the filter\n",
    "    vector_store = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "    \n",
    "    # Create retriever with the specified search type and filter\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=search_type,\n",
    "        search_kwargs=search_kwargs\n",
    "    )\n",
    "    \n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize callback manager for tracing\n",
    "def get_tracer_callback_manager():\n",
    "    tracer = LangChainTracer(project_name=os.environ.get(\"LANGCHAIN_PROJECT\", \"steam-reviews-rag\"))\n",
    "    return CallbackManager([tracer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated RAG system setup with game name extraction\n",
    "@traceable(name=\"setup_rag_system\")\n",
    "def setup_rag_system(collection_name=\"steam_reviews\", k=25, model=\"gpt-4o-mini\", temperature=0):\n",
    "    \"\"\"\n",
    "    Set up RAG system with the ability to filter by game name if specified in queries.\n",
    "    \"\"\"\n",
    "    # Set up client for game name extraction\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "    \n",
    "    # We'll set up the retriever in the query function after game extraction\n",
    "    \n",
    "    # Set up prompt template\n",
    "    template = \"\"\"You are an AI assistant helping game developers improve their games based on Steam reviews.\n",
    "    Use the following pieces of context (review excerpts) to answer the question.\n",
    "    If you don't know the answer, just say that you don't know. If the question is not related to the game, just say that you don't know. \n",
    "    If the question is about a game not explicitly present in the context, just say that you don't know. \n",
    "    Always verify that the game specified in the question is present in the context before answering. \n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    PROMPT = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    # Set up LLM with tracing\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=temperature, \n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # Create a wrapper class that will extract game name on each query\n",
    "    class GameFilteredRAG:\n",
    "        def __init__(self, llm, prompt, client, collection_name, k):\n",
    "            self.llm = llm\n",
    "            self.prompt = prompt\n",
    "            self.client = client\n",
    "            self.collection_name = collection_name\n",
    "            self.k = k\n",
    "        \n",
    "        def invoke(self, params):\n",
    "            query = params.get(\"query\", \"\")\n",
    "            \n",
    "            # Extract game name from query\n",
    "            game_name = extract_game_name(query, games_csv_path=\"games.csv\")\n",
    "            \n",
    "            # Set up retriever with game filter if applicable\n",
    "            retriever = setup_rag_retriever(\n",
    "                collection_name=self.collection_name, \n",
    "                k=self.k,\n",
    "                game_name=game_name\n",
    "            )\n",
    "            \n",
    "            # Create QA chain with the configured retriever\n",
    "            qa = RetrievalQA.from_chain_type(\n",
    "                llm=self.llm,\n",
    "                retriever=retriever,\n",
    "                chain_type_kwargs={\"prompt\": self.prompt},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # Log which game is being filtered (if any)\n",
    "            if game_name:\n",
    "                print(f\"Filtering results for game: {game_name}\")\n",
    "            else:\n",
    "                print(\"No specific game detected in query. Searching across all games.\")\n",
    "            \n",
    "            # Execute query\n",
    "            result = qa.invoke({\"query\": query})\n",
    "            return result\n",
    "    \n",
    "    # Create and return our custom RAG implementation\n",
    "    return GameFilteredRAG(llm, PROMPT, client, collection_name, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to run RAG query with game filtering\n",
    "@traceable(name=\"run_rag_query\")\n",
    "def run_rag_query(qa_system, query):\n",
    "    \"\"\"\n",
    "    Run a RAG query with game name filtering and comprehensive tracing for performance analysis\n",
    "    \"\"\"\n",
    "    # Execute query using invoke method instead of __call__\n",
    "    result = qa_system.invoke({\"query\": query})\n",
    "    \n",
    "    # Calculate result metrics\n",
    "    run_metrics = {\n",
    "        \"query\": query,\n",
    "        \"result_length\": len(result.get(\"result\", \"\")),\n",
    "        \"num_source_docs\": len(result.get(\"source_documents\", [])),\n",
    "    }\n",
    "    \n",
    "    return result, run_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/gyqgx68n4v72zw8nb1r3jrj80000gn/T/ipykernel_40060/3219850533.py:31: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n",
      "/var/folders/3m/gyqgx68n4v72zw8nb1r3jrj80000gn/T/ipykernel_40060/858501952.py:43: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.1.2 and will be removed in 0.5.0. Use :class:`~QdrantVectorStore` instead.\n",
      "  vector_store = Qdrant(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for game: Counter-Strike\n",
      "Filtering results for game: Counter-Strike\n",
      "Result: I don't know.\n",
      "Metrics: {'query': 'What is the most commong complaint about Counter-Strike?', 'result_length': 13, 'num_source_docs': 0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Check if LangSmith credentials are set\n",
    "    if not os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
    "        print(\"Warning: LANGCHAIN_API_KEY not set. LangSmith tracing will not work.\")\n",
    "        quit \n",
    "        \n",
    "    # Set up the RAG system with tracing\n",
    "    qa_chain = setup_rag_system(collection_name=\"steam_reviews\", k=250)\n",
    "    \n",
    "    # Run a query with detailed performance tracing\n",
    "    query = \"What is the most commong complaint about Counter-Strike?\"\n",
    "    result, metrics = run_rag_query(qa_chain, query)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Result: {result['result']}\")\n",
    "    print(f\"Metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
